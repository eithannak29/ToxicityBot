\chapter{Transformers}

\section{Construction du modèle}

Afin d'améliorer les performances de notre solution, nous avons décidé de tester un modèle transformer.
Pour ce faire nous avons utilisé la librairie Hugging Face qui propose des implémentations de modèles transformer pré-entraînés.
Nous avons choisi d'utiliser le modèle DistilBert qui est une version plus légère du modèle BERT qui a été pré-entraîné sur des données textuelles massives.
Cette version plus légère permet de réduire le temps d'entraînement et la consommation de mémoire tout en conservant 97\% des performances du modèle BERT.

\subsection{Prétraitement des données}

Pour prétraiter les données textuelles, nous avons utilisé le tokenizer DistilBertTokenizer qui permet de transformer les textes en tokens qui peuvent être compris par le modèle DistilBert.

\subsection{Architecture du modèle}

Nous avons utilisé le modèle transformeur DistilBERT, un modèle allégé de BERT, pour notre tâche de classification multilabel. Voici les spécificités de l'architecture du modèle :

\begin{itemize}
\item DistilBERT conserve les performances de BERT tout en étant plus rapide et plus léger.
\item Il est constitué de plusieurs couches de transformeurs pour capturer les représentations contextuelles des mots.
\item Le modèle a été adapté pour notre tâche avec une couche de sortie de dimension 6 et une fonction d'activation sigmoïde, permettant la classification multilabel des catégories.
\item La fonction de coût utilisée est la perte de log-vraisemblance négative (\texttt{BCEWithLogitsLoss}), adaptée aux tâches de classification multilabel.
\item L'optimisation a été réalisée à l'aide de l'algorithme Adam, une méthode efficace pour les grands ensembles de données et les réseaux de neurones complexes.
\end{itemize}

\section{Résultats}

Voici les scores de précision, de rappel et de F1-Score par label, d'un modèle DistilBERT pré-entraîné sur des données textuelles massives, pour la classification multilabel des différentes catégories au bout de 10 époques.

\begin{table}[ht]
    \centering
    \caption{Scores de Précision, Rappel, et F1-Score par Label, d'un modèle DistilBERT \textbf{sans} la pondération des classes, sur le jeu de test}    \begin{tabular}{lcccc}
    \hline
    \textbf{Label} & \textbf{Précision} & \textbf{Rappel} & \textbf{F1-Score} & \textbf{Support} \\ \hline
    toxic          & 0.52               & 0.91            & 0.66              & 6090             \\
    severe\_toxic  & 0.40               & 0.38            & 0.39              & 367              \\
    obscene        & 0.59               & 0.82            & 0.69              & 3691             \\
    threat         & 0.46               & 0.57            & 0.51              & 211              \\
    insult         & 0.62               & 0.78            & 0.69              & 3427             \\
    identity\_hate & 0.63               & 0.61            & 0.62              & 712              \\
    overall\_non\_toxic & 0.99           & 0.91            & 0.95              & 57735            \\\hline
    macro avg      & 0.60              & 0.71            & 0.64              & 72233            \\
    weighted avg   & 0.90               & 0.90            & 0.89             & 72233            \\ \hline
    \end{tabular}
    \label{tab:scores}
\end{table}


\begin{table}[ht]
    \centering
    \caption{Scores de Précision, Rappel, et F1-Score par Label, d'un modèle DistilBERT \textbf{avec} la pondération des classes, sur le jeu de test}    \begin{tabular}{lcccc}
    \hline
    \textbf{Label} & \textbf{Précision} & \textbf{Rappel} & \textbf{F1-Score} & \textbf{Support} \\ \hline
    toxic          & 0.52               & 0.91            & 0.66              & 6090             \\
    severe\_toxic  & 0.40               & 0.38            & 0.39              & 367              \\
    obscene        & 0.59               & 0.82            & 0.69              & 3691             \\
    threat         & 0.46               & 0.57            & 0.51              & 211              \\
    insult         & 0.62               & 0.78            & 0.69              & 3427             \\
    identity\_hate & 0.63               & 0.61            & 0.62              & 712              \\
    overall\_non\_toxic & 0.99           & 0.91            & 0.95              & 57735            \\\hline
    macro avg      & 0.60              & 0.71            & 0.64              & 72233            \\
    weighted avg   & 0.90               & 0.90            & 0.89             & 72233            \\ \hline
    \end{tabular}
    \label{tab:scores}
\end{table}