\chapter{Transformers}

\section{Construction du modèle}

Afin d'améliorer les performances de notre solution, nous avons décidé de tester un modèle \textit{transformer}.
Pour ce faire nous avons utilisé la bibliothèque \textit{Hugging Face} qui propose des implémentations de modèles \textit{transformer} préentraînés.
Nous avons choisi d'utiliser le modèle \textit{BERT} qui a été préentraîné sur des données textuelles massives et qui a montré de très bonnes performances sur de nombreuses tâches de traitement du langage naturel.
Nous avons entraîné le modèle sur notre jeu de données pour réaliser une classification multilabel des commentaires à l'aide de \textit{Google Colab}.

\subsection{Prétraitement des données}

Pour prétraiter les données textuelles, nous avons utilisé le \textit{tokenizer} \textit{BERTTokenizer} qui permet de \textit{transformer} les textes en \textit{tokens} qui peuvent être compris par le modèle \textit{BERT}.

\subsection{Architecture du modèle}

Nous avons utilisé le modèle transformeur \textit{BERT}, un modèle allégé de \textit{BERT}, pour notre tâche de classification multilabel. Voici les spécificités de l'architecture du modèle :

\begin{itemize}
\item Il est constitué de plusieurs couches de transformeurs pour capturer les représentations contextuelles des mots.
\item Le modèle a été adapté pour notre tâche avec une couche de sortie de dimension \textbf{6} et une fonction d'activation sigmoïde, permettant la classification multilabel des catégories.
\item La fonction de coût utilisée est la perte de log-vraisemblance négative (\textit{BCEWithLogitsLoss}), adaptée aux tâches de classification multilabel.
\item L'optimisation a été réalisée à l'aide de l'algorithme Adam, une méthode efficace pour les grands ensembles de données et les réseaux de neurones complexes.
\end{itemize}

\section{Résultats}

Voici les scores de précision, de rappel et de F1-Score par label, d'un modèle \textit{BERT} préentraîné sur des données textuelles massives, pour la classification multilabel des différentes catégories au bout de \textbf{10} \textit{epochs}.

\begin{table}[ht]
    \centering
    \caption{Scores de Précision, Rappel, et F1-Score par Label, d'un modèle \textit{BERT} \textbf{sans} la pondération des classes, sur le jeu de test}    \begin{tabular}{lcccc}
    \hline
    \textbf{Label} & \textbf{Précision} & \textbf{Rappel} & \textbf{F1-Score} & \textbf{Support} \\ \hline
    toxic          & 0.52               & 0.91            & 0.66              & 6090             \\
    severe\_toxic  & 0.40               & 0.38            & 0.39              & 367              \\
    obscene        & 0.59               & 0.82            & 0.69              & 3691             \\
    threat         & 0.46               & 0.57            & 0.51              & 211              \\
    insult         & 0.62               & 0.78            & 0.69              & 3427             \\
    identity\_hate & 0.63               & 0.61            & 0.62              & 712              \\
    overall\_non\_toxic & 0.99           & 0.91            & 0.95              & 57735            \\\hline
    macro avg      & 0.60              & 0.71            & 0.64              & 72233            \\
    weighted avg   & 0.90               & 0.90            & 0.89             & 72233            \\ \hline
    \end{tabular}
    \label{tab:scores}
\end{table}


\begin{table}[ht]
    \centering
    \caption{Scores de Précision, Rappel, et F1-Score par Label, d'un modèle \textit{BERT} \textbf{avec} la pondération des classes, sur le jeu de test}    \begin{tabular}{lcccc}
    \hline
    \textbf{Label} & \textbf{Précision} & \textbf{Rappel} & \textbf{F1-Score} & \textbf{Support} \\ \hline
    toxic          & 0.52               & 0.91            & 0.66              & 6090             \\
    severe\_toxic  & 0.40               & 0.38            & 0.39              & 367              \\
    obscene        & 0.59               & 0.82            & 0.69              & 3691             \\
    threat         & 0.46               & 0.57            & 0.51              & 211              \\
    insult         & 0.62               & 0.78            & 0.69              & 3427             \\
    identity\_hate & 0.63               & 0.61            & 0.62              & 712              \\
    overall\_non\_toxic & 0.99           & 0.91            & 0.95              & 57735            \\\hline
    macro avg      & 0.60              & 0.71            & 0.64              & 72233            \\
    weighted avg   & 0.90               & 0.90            & 0.89             & 72233            \\ \hline
    \end{tabular}
    \label{tab:scores}
\end{table}