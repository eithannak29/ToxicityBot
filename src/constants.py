TEST_LABEL_PATH = 'C:\\Users\\Samy\\Desktop\\NLP\\newRepo\\ToxicityBot\\src\\data\\test_labels.csv'
TEST_PATH = 'C:\\Users\\Samy\\Desktop\\NLP\\newRepo\\ToxicityBot\\src\\data\\test.csv'
TRAIN_PATH = 'C:\\Users\\Samy\\Desktop\\NLP\\newRepo\\ToxicityBot\\src\\data\\train.csv'

CATEGORIES = ["toxic","severe_toxic","obscene", "threat", "insult", "identity_hate"]
TEST_LABEL_PATH = 'jigsaw-toxic-comment-classification-challenge/test_labels.csv'
TEST_PATH = 'jigsaw-toxic-comment-classification-challenge/test.csv'
TRAIN_PATH = 'jigsaw-toxic-comment-classification-challenge/train.csv'

CATEGORIES = ["toxic","severe_toxic","obscene", "threat", "insult", "identity_hate"]