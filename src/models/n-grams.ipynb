{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "sys.path.append('../utils/')\n",
    "sys.path.append('..')\n",
    "from preprocessing import load_preprocessed_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des données prétraitées\n",
    "Ici on charge les ensembles de données d'entraînement, de validation et de test en utilisant une fonction personnalisée définie dans le module de prétraitement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 sec TO LOAD\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'data'\n",
    "df_train, df_val, df_test = load_preprocessed_dataframe(output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affichage des exemples de commentaires\n",
    "Ici on affiche quelques exemples de commentaires du jeu de données d'entraînement pour avoir un aperçu des données textuelles sur lesquelles nous travaillons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140030    Grandma Terri Should Burn in Trash \\nGrandma T...\n",
      "159124    , 9 May 2009 (UTC)\\nIt would be easiest if you...\n",
      "60006     \"\\n\\nThe Objectivity of this Discussion is dou...\n",
      "65432                 Shelly Shock\\nShelly Shock is. . .( )\n",
      "154979    I do not care. Refer to Ong Teng Cheong talk p...\n",
      "                                ...                        \n",
      "119879    REDIRECT Talk:John Loveday (experimental physi...\n",
      "103694    Back it up. Post the line here with the refere...\n",
      "131932    I won't stop that. Sometimes Germanic equals G...\n",
      "146867    \"\\n\\n British Bands?  \\n\\nI think you've mista...\n",
      "121958    You are WRONG. \\n\\nJustin Thompson is mentione...\n",
      "Name: comment_text_baseline, Length: 127656, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_train[\"comment_text_baseline\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenation des textes\n",
    "Ici on concatène les commentaires des ensembles de données d'entraînement, de validation et de test en une seule liste de phrases, puis affiche la longueur totale de cette liste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223549"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming df_train, df_val, df_test contain a column 'text' with the sentences.\n",
    "all_texts = pd.concat([df_train['comment_text_baseline'], df_val['comment_text_baseline'], df_test['comment_text_baseline']])\n",
    "sentences = all_texts.tolist()\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du modèle de bigrammes\n",
    "Ici on utilise `CountVectorizer` pour créer un modèle de bigrammes (séquences de deux mots) à partir des phrases. Le modèle est ensuite ajusté sur les phrases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b', ngram_range=(2, 2))\n",
    "X = vectorizer.fit_transform(sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul et affichage de la fréquence des bigrammes\n",
    "Ici on calcule la fréquence de chaque bigramme dans le corpus et définit une fonction pour prédire le mot suivant basé sur un mot précédent en utilisant les bigrammes les plus fréquents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Count the frequency of each bigram\n",
    "bigram_frequency = np.asarray(X.sum(axis=0)).ravel()\n",
    "\n",
    "# Map each bigram to its frequency\n",
    "bigram_to_freq = dict(zip(vectorizer.get_feature_names_out(), bigram_frequency))\n",
    "\n",
    "# Sort the bigram_to_freq dictionary by frequency in descending order and print the top 10 bigrams\n",
    "#for bigram, freq in sorted(bigram_to_freq.items(), key=lambda item: item[1], reverse=True)[:10]:\n",
    "#    print(f\"Bigram: '{bigram}', Frequency: {freq}\")\n",
    "\n",
    "# Function to predict the next word\n",
    "def predict_next_word(previous_word):\n",
    "    candidates = {bigram: freq for bigram, freq in bigram_to_freq.items() if bigram.startswith(previous_word + ' ')}\n",
    "    \n",
    "    sorted_candidates = {k: v for k, v in sorted(candidates.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "    \n",
    "    #for bigram, freq in sorted_candidates.items():\n",
    "        #print(f\"Bigram: '{bigram}', Frequency: {freq}\")\n",
    "\n",
    "    if not candidates:\n",
    "        return \"No prediction available\"\n",
    "    return max(candidates, key=candidates.get).split()[1]\n",
    "\n",
    "# Example\n",
    "print(predict_next_word(\"you\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du modèle de trigrammes\n",
    "Ici on utilise `CountVectorizer` pour créer un modèle de trigrammes (séquences de trois mots) à partir des phrases. Le modèle est ensuite ajusté sur les phrases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m vectorizer_3gram \u001b[38;5;241m=\u001b[39m CountVectorizer(token_pattern\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m X_3gram \u001b[38;5;241m=\u001b[39m \u001b[43mvectorizer_3gram\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Samy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Samy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1389\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1381\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1382\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1384\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1385\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1386\u001b[0m             )\n\u001b[0;32m   1387\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1389\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1392\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Samy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1313\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1311\u001b[0m     indices_dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mint32\n\u001b[0;32m   1312\u001b[0m j_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(j_indices, dtype\u001b[38;5;241m=\u001b[39mindices_dtype)\n\u001b[1;32m-> 1313\u001b[0m indptr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(indptr, dtype\u001b[38;5;241m=\u001b[39mindices_dtype)\n\u001b[0;32m   1314\u001b[0m values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(values, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintc)\n\u001b[0;32m   1316\u001b[0m X \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcsr_matrix(\n\u001b[0;32m   1317\u001b[0m     (values, j_indices, indptr),\n\u001b[0;32m   1318\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mlen\u001b[39m(indptr) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(vocabulary)),\n\u001b[0;32m   1319\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m   1320\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vectorizer_3gram = CountVectorizer(token_pattern=r'\\b\\w+\\b', ngram_range=(3, 3))\n",
    "X_3gram = vectorizer_3gram.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul et affichage de la fréquence des trigrammes\n",
    "Ici on calcule la fréquence de chaque trigramme dans le corpus et définit une fonction pour prédire le mot suivant basé sur les deux mots précédents en utilisant les trigrammes les plus fréquents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trgram: 'upon a time', Frequency: 26\n",
      "Trgram: 'upon a non', Frequency: 3\n",
      "Trgram: 'upon a person', Frequency: 3\n",
      "Trgram: 'upon a fascinating', Frequency: 2\n",
      "Trgram: 'upon a full', Frequency: 2\n",
      "Trgram: 'upon a quick', Frequency: 2\n",
      "Trgram: 'upon a scarlet', Frequency: 2\n",
      "Trgram: 'upon a 19', Frequency: 1\n",
      "Trgram: 'upon a bit', Frequency: 1\n",
      "Trgram: 'upon a consent', Frequency: 1\n",
      "time\n"
     ]
    }
   ],
   "source": [
    "# Count the frequency of each bigram\n",
    "trigram_frequency = np.asarray(X_3gram.sum(axis=0)).ravel()\n",
    "\n",
    "# Map each bigram to its frequency\n",
    "trigram_to_freq = dict(zip(vectorizer_3gram.get_feature_names_out(), trigram_frequency))\n",
    "\n",
    "# Sort the bigram_to_frq dictionary by frequency in descending order and print the top 10 bigrams\n",
    "#for trigram, freq in sorted(trigram_to_freq.items(), key=lambda item: item[1], reverse=True)[:10]:\n",
    "    #print(f\"Bigram: '{trigram}', Frequency: {freq}\")\n",
    "\n",
    "# Function to predict the next word based on the two previous words\n",
    "def predict_next_word_trigram(previous_words):\n",
    "    previous_words = previous_words.lower()\n",
    "    candidates = {trigram: freq for trigram, freq in trigram_to_freq.items() if trigram.startswith(previous_words + ' ')}\n",
    "\n",
    "    sorted_candidates = {k: v for k, v in sorted(candidates.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "    # Now, print the sorted candidates\n",
    "    i = 0\n",
    "    for trigram, freq in sorted_candidates.items():\n",
    "        print(f\"Trgram: '{trigram}', Frequency: {freq}\")\n",
    "        i += 1\n",
    "        if (i == 10):\n",
    "            break\n",
    "\n",
    "    if not candidates:\n",
    "        return \"No prediction available\"\n",
    "    # Extracting the last word of the most frequent trigram following the previous_words\n",
    "    return max(candidates, key=candidates.get).split()[2]\n",
    "\n",
    "print(predict_next_word_trigram(\"upon a\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complétion de phrase avec les bigrammes\n",
    "Ici on définit une fonction pour compléter une phrase en utilisant les bigrammes les plus fréquents. Elle prédit les mots suivants jusqu'à atteindre la longueur maximale spécifiée.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you like playing the article is a few days\n"
     ]
    }
   ],
   "source": [
    "def complete_the_phrase(starting_phrase, max_length=10):\n",
    "    current_phrase = starting_phrase.strip()\n",
    "    words = current_phrase.split()\n",
    "    \n",
    "    # Continue until reaching the maximum length\n",
    "    for _ in range(max_length - len(words)):\n",
    "        last_word = words[-1]\n",
    "        # Find candidates that start with the last word of the current phrase\n",
    "        candidates = {bigram: freq for bigram, freq in bigram_to_freq.items() if bigram.startswith(last_word + ' ')}\n",
    "        if not candidates:\n",
    "            break  # No candidates found, stop the loop\n",
    "        # Pick the most frequent continuation (the second word in the bigram)\n",
    "        next_word = sorted(candidates.items(), key=lambda item: item[1], reverse=True)[0][0].split()[1]\n",
    "        words.append(next_word)\n",
    "    \n",
    "    return ' '.join(words)\n",
    "\n",
    "# Example usage:\n",
    "print(complete_the_phrase(\"Do you like playing\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complétion de phrase avec les trigrammes\n",
    "Ici on définit une fonction pour compléter une phrase en utilisant les trigrammes les plus fréquents. Elle prédit les mots suivants jusqu'à atteindre la longueur maximale spécifiée.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "once upon a time when i was just a few days ago i m not\n"
     ]
    }
   ],
   "source": [
    "def complete_the_phrase_trigram(starting_phrase, max_length=15):\n",
    "    current_phrase = starting_phrase.strip()\n",
    "    words = current_phrase.split()\n",
    "    \n",
    "    # Ensure there are enough words for trigram prediction\n",
    "    if len(words) < 2:\n",
    "        return \"Please provide at least two words for the initial phrase.\"\n",
    "    \n",
    "    # Continue until reaching the maximum length\n",
    "    for _ in range(max_length - len(words)):\n",
    "        # Use the last two words for the trigram prediction\n",
    "        last_two_words = ' '.join(words[-2:])\n",
    "        # Find candidates that start with the last two words of the current phrase\n",
    "        candidates = {trigram: freq for trigram, freq in trigram_to_freq.items() if trigram.startswith(last_two_words + ' ')}\n",
    "        if not candidates:\n",
    "            break  # No candidates found, stop the loop\n",
    "        # Pick the most frequent continuation (the third word in the trigram)\n",
    "        next_word = sorted(candidates.items(), key=lambda item: item[1], reverse=True)[0][0].split()[2]\n",
    "        words.append(next_word)\n",
    "    \n",
    "    return ' '.join(words)\n",
    "\n",
    "# Example usage:\n",
    "print(complete_the_phrase_trigram(\"once upon\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classe NGramPredictor\n",
    "Ici on définit une classe `NGramPredictor` pour créer un modèle de n-grammes (séquences de n mots) avec des méthodes pour ajuster le modèle sur des phrases, prédire le mot suivant et compléter une phrase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramPredictor:\n",
    "    def __init__(self, n=2):\n",
    "        self.n = n\n",
    "        self.vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b', ngram_range=(n, n))\n",
    "        self.ngram_to_freq = {}\n",
    "\n",
    "    def fit(self, sentences):\n",
    "        X_ngram = self.vectorizer.fit_transform(sentences)\n",
    "        ngram_frequency = np.asarray(X_ngram.sum(axis=0)).ravel()\n",
    "        self.ngram_to_freq = dict(zip(self.vectorizer.get_feature_names_out(), ngram_frequency))\n",
    "\n",
    "    def predict_next_word(self, previous_words):\n",
    "        previous_words = ' '.join(previous_words.split()[-(self.n-1):]).lower()\n",
    "        candidates = {ngram: freq for ngram, freq in self.ngram_to_freq.items() if ngram.startswith(previous_words + ' ')}\n",
    "        \n",
    "        if not candidates:\n",
    "            return None  # Changed to return None for easier checking\n",
    "        \n",
    "        return max(candidates, key=candidates.get).split()[-1]\n",
    "\n",
    "    def complete_the_phrase(self, starting_phrase, max_length=10):\n",
    "        current_phrase = starting_phrase.strip()\n",
    "        words = current_phrase.split()\n",
    "        \n",
    "        # Adjust for n-gram model\n",
    "        for _ in range(max_length - len(words)):\n",
    "            if len(words) < self.n - 1:\n",
    "                return \"Please provide more words for the initial phrase.\"\n",
    "            \n",
    "            # For n-grams, use the last n-1 words as context\n",
    "            previous_words = ' '.join(words[-(self.n-1):])\n",
    "            next_word = self.predict_next_word(previous_words)\n",
    "            \n",
    "            if not next_word:\n",
    "                break  # No candidates found, stop the loop\n",
    "            \n",
    "            words.append(next_word)\n",
    "        \n",
    "        return ' '.join(words)\n",
    "    \n",
    "    def print_top_ngrams(self, top=10):\n",
    "        for ngram, freq in sorted(self.ngram_to_freq.items(), key=lambda item: item[1], reverse=True)[:top]:\n",
    "            print(f\"N-Gram: '{ngram}', Frequency: {freq}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemple d'utilisation du NGramPredictor\n",
    "Ici on crée une instance de la classe `NGramPredictor` pour les trigrammes et ajuste le modèle sur les phrases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "ngram_predictor = NGramPredictor(n=4)  # For trigrams\n",
    "ngram_predictor.fit(sentences)  # Assuming 'sentences' is a list of sentence strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affichage des n-grammes les plus fréquents et complétion de phrase\n",
    "Ici on affiche les n-grammes les plus fréquents et utilise la méthode `complete_the_phrase` de la classe `NGramPredictor` pour compléter une phrase donnée.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-Gram: 'nigger nigger nigger nigger', Frequency: 3411\n",
      "N-Gram: 'on my talk page', Frequency: 3067\n",
      "N-Gram: 'be blocked from editing', Frequency: 2761\n",
      "N-Gram: 'fuck you fuck you', Frequency: 2681\n",
      "N-Gram: 'you fuck you fuck', Frequency: 2623\n",
      "N-Gram: 'i don t know', Frequency: 2621\n",
      "N-Gram: 'you will be blocked', Frequency: 2549\n",
      "N-Gram: 'if you continue to', Frequency: 2486\n",
      "N-Gram: 'if you have any', Frequency: 2483\n",
      "N-Gram: 'i don t think', Frequency: 2464\n",
      "once upon a time in a steppe far far away\n"
     ]
    }
   ],
   "source": [
    "ngram_predictor.print_top_ngrams()\n",
    "print(ngram_predictor.complete_the_phrase(\"once upon a\", max_length=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Évaluation du modèle\n",
    "Ici on définit une fonction pour évaluer la précision du modèle sur les phrases de test. Elle compare les prédictions du modèle avec les mots réels et calcule la précision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_sentences):\n",
    "    print(len(test_sentences))\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    counter = 0\n",
    "    for sentence in test_sentences:\n",
    "        counter += 1\n",
    "        words = sentence.split()\n",
    "        # Ensure the sentence has more words than n-1 to make a prediction and have a target\n",
    "        if len(words) >= model.n:\n",
    "            for i in range(model.n - 1, len(words)):\n",
    "                context = ' '.join(words[max(0, i - model.n + 1):i])\n",
    "                actual_next_word = words[i]\n",
    "                predicted_next_word = model.predict_next_word(context)\n",
    "                \n",
    "                if predicted_next_word is not None and predicted_next_word == actual_next_word:\n",
    "                    correct_predictions += 1\n",
    "                total_predictions += 1\n",
    "\n",
    "                if (predicted_next_word is None):\n",
    "                    print (\"None \")\n",
    "                else:\n",
    "                    print(\"Context: \" + context + \" - Expected: \" + words[i] + \" Predicted: \" + predicted_next_word + \" \" + str(counter))\n",
    "        if (counter >= 100):\n",
    "            break\n",
    "    \n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage des phrases que l'on va tester !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thank you for understanding. I think very highly of you and would not revert without discussion.']\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have an instance of NGramPredictor called 'ngram_predictor' and it's already fit\n",
    "# And assuming 'sentences' is your list of test sentences:\n",
    "test_sentences = df_test['comment_text_baseline'].to_list()\n",
    "test_sentences = test_sentences[:1]\n",
    "print(test_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement et creation du model N-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "tested_predictor = NGramPredictor(n=4)  # For trigrams\n",
    "tested_predictor.fit(sentences)  # Assuming 'sentences' is a list of sentence strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul de l'accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Context: Thank you for - Expected: understanding. Predicted: your 1\n",
      "None \n",
      "None \n",
      "None \n",
      "Context: I think very - Expected: highly Predicted: early 1\n",
      "Context: think very highly - Expected: of Predicted: of 1\n",
      "Context: very highly of - Expected: you Predicted: the 1\n",
      "Context: highly of you - Expected: and Predicted: and 1\n",
      "Context: of you and - Expected: would Predicted: your 1\n",
      "Context: you and would - Expected: not Predicted: not 1\n",
      "Context: and would not - Expected: revert Predicted: be 1\n",
      "Context: would not revert - Expected: without Predicted: a 1\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluate_model(tested_predictor, test_sentences)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
