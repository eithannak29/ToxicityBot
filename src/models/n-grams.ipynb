{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Samy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Samy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Samy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Samy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "sys.path.append('../utils/')\n",
    "sys.path.append('..')\n",
    "from preprocessing import load_preprocessed_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des données prétraitées\n",
    "Ici on charge les ensembles de données d'entraînement, de validation et de test en utilisant une fonction personnalisée définie dans le module de prétraitement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 sec TO LOAD\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'data'\n",
    "df_train, df_val, df_test = load_preprocessed_dataframe(output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affichage des exemples de commentaires\n",
    "Ici on affiche quelques exemples de commentaires du jeu de données d'entraînement pour avoir un aperçu des données textuelles sur lesquelles nous travaillons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140030    Grandma Terri Should Burn in Trash \\nGrandma T...\n",
      "159124    , 9 May 2009 (UTC)\\nIt would be easiest if you...\n",
      "60006     \"\\n\\nThe Objectivity of this Discussion is dou...\n",
      "65432                 Shelly Shock\\nShelly Shock is. . .( )\n",
      "154979    I do not care. Refer to Ong Teng Cheong talk p...\n",
      "                                ...                        \n",
      "119879    REDIRECT Talk:John Loveday (experimental physi...\n",
      "103694    Back it up. Post the line here with the refere...\n",
      "131932    I won't stop that. Sometimes Germanic equals G...\n",
      "146867    \"\\n\\n British Bands?  \\n\\nI think you've mista...\n",
      "121958    You are WRONG. \\n\\nJustin Thompson is mentione...\n",
      "Name: comment_text_baseline, Length: 127656, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_train[\"comment_text_baseline\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenation des textes\n",
    "Ici on concatène les commentaires des ensembles de données d'entraînement, de validation et de test en une seule liste de phrases, puis affiche la longueur totale de cette liste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223549"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming df_train, df_val, df_test contain a column 'text' with the sentences.\n",
    "all_texts = pd.concat([df_train['comment_text_baseline'], df_val['comment_text_baseline'], df_test['comment_text_baseline']])\n",
    "sentences = all_texts.tolist()\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du modèle de bigrammes\n",
    "Ici on utilise `CountVectorizer` pour créer un modèle de bigrammes (séquences de deux mots) à partir des phrases. Le modèle est ensuite ajusté sur les phrases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b', ngram_range=(2, 2))\n",
    "X = vectorizer.fit_transform(sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul et affichage de la fréquence des bigrammes\n",
    "Ici on calcule la fréquence de chaque bigramme dans le corpus et définit une fonction pour prédire le mot suivant basé sur un mot précédent en utilisant les bigrammes les plus fréquents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Count the frequency of each bigram\n",
    "bigram_frequency = np.asarray(X.sum(axis=0)).ravel()\n",
    "\n",
    "# Map each bigram to its frequency\n",
    "bigram_to_freq = dict(zip(vectorizer.get_feature_names_out(), bigram_frequency))\n",
    "\n",
    "# Sort the bigram_to_freq dictionary by frequency in descending order and print the top 10 bigrams\n",
    "#for bigram, freq in sorted(bigram_to_freq.items(), key=lambda item: item[1], reverse=True)[:10]:\n",
    "#    print(f\"Bigram: '{bigram}', Frequency: {freq}\")\n",
    "\n",
    "# Function to predict the next word\n",
    "def predict_next_word(previous_word):\n",
    "    candidates = {bigram: freq for bigram, freq in bigram_to_freq.items() if bigram.startswith(previous_word + ' ')}\n",
    "    \n",
    "    sorted_candidates = {k: v for k, v in sorted(candidates.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "    \n",
    "    #for bigram, freq in sorted_candidates.items():\n",
    "        #print(f\"Bigram: '{bigram}', Frequency: {freq}\")\n",
    "\n",
    "    if not candidates:\n",
    "        return \"No prediction available\"\n",
    "    return max(candidates, key=candidates.get).split()[1]\n",
    "\n",
    "# Example\n",
    "print(predict_next_word(\"you\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du modèle de trigrammes\n",
    "Ici on utilise `CountVectorizer` pour créer un modèle de trigrammes (séquences de trois mots) à partir des phrases. Le modèle est ensuite ajusté sur les phrases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_3gram = CountVectorizer(token_pattern=r'\\b\\w+\\b', ngram_range=(3, 3))\n",
    "X_3gram = vectorizer_3gram.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul et affichage de la fréquence des trigrammes\n",
    "Ici on calcule la fréquence de chaque trigramme dans le corpus et définit une fonction pour prédire le mot suivant basé sur les deux mots précédents en utilisant les trigrammes les plus fréquents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trgram: 'upon a time', Frequency: 26\n",
      "Trgram: 'upon a non', Frequency: 3\n",
      "Trgram: 'upon a person', Frequency: 3\n",
      "Trgram: 'upon a fascinating', Frequency: 2\n",
      "Trgram: 'upon a full', Frequency: 2\n",
      "Trgram: 'upon a quick', Frequency: 2\n",
      "Trgram: 'upon a scarlet', Frequency: 2\n",
      "Trgram: 'upon a 19', Frequency: 1\n",
      "Trgram: 'upon a bit', Frequency: 1\n",
      "Trgram: 'upon a consent', Frequency: 1\n",
      "time\n"
     ]
    }
   ],
   "source": [
    "# Count the frequency of each bigram\n",
    "trigram_frequency = np.asarray(X_3gram.sum(axis=0)).ravel()\n",
    "\n",
    "# Map each bigram to its frequency\n",
    "trigram_to_freq = dict(zip(vectorizer_3gram.get_feature_names_out(), trigram_frequency))\n",
    "\n",
    "# Sort the bigram_to_frq dictionary by frequency in descending order and print the top 10 bigrams\n",
    "#for trigram, freq in sorted(trigram_to_freq.items(), key=lambda item: item[1], reverse=True)[:10]:\n",
    "    #print(f\"Bigram: '{trigram}', Frequency: {freq}\")\n",
    "\n",
    "# Function to predict the next word based on the two previous words\n",
    "def predict_next_word_trigram(previous_words):\n",
    "    previous_words = previous_words.lower()\n",
    "    candidates = {trigram: freq for trigram, freq in trigram_to_freq.items() if trigram.startswith(previous_words + ' ')}\n",
    "\n",
    "    sorted_candidates = {k: v for k, v in sorted(candidates.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "    # Now, print the sorted candidates\n",
    "    i = 0\n",
    "    for trigram, freq in sorted_candidates.items():\n",
    "        print(f\"Trgram: '{trigram}', Frequency: {freq}\")\n",
    "        i += 1\n",
    "        if (i == 10):\n",
    "            break\n",
    "\n",
    "    if not candidates:\n",
    "        return \"No prediction available\"\n",
    "    # Extracting the last word of the most frequent trigram following the previous_words\n",
    "    return max(candidates, key=candidates.get).split()[2]\n",
    "\n",
    "print(predict_next_word_trigram(\"upon a\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complétion de phrase avec les bigrammes\n",
    "Ici on définit une fonction pour compléter une phrase en utilisant les bigrammes les plus fréquents. Elle prédit les mots suivants jusqu'à atteindre la longueur maximale spécifiée.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you like playing the article is a few days\n"
     ]
    }
   ],
   "source": [
    "def complete_the_phrase(starting_phrase, max_length=10):\n",
    "    current_phrase = starting_phrase.strip()\n",
    "    words = current_phrase.split()\n",
    "    \n",
    "    # Continue until reaching the maximum length\n",
    "    for _ in range(max_length - len(words)):\n",
    "        last_word = words[-1]\n",
    "        # Find candidates that start with the last word of the current phrase\n",
    "        candidates = {bigram: freq for bigram, freq in bigram_to_freq.items() if bigram.startswith(last_word + ' ')}\n",
    "        if not candidates:\n",
    "            break  # No candidates found, stop the loop\n",
    "        # Pick the most frequent continuation (the second word in the bigram)\n",
    "        next_word = sorted(candidates.items(), key=lambda item: item[1], reverse=True)[0][0].split()[1]\n",
    "        words.append(next_word)\n",
    "    \n",
    "    return ' '.join(words)\n",
    "\n",
    "# Example usage:\n",
    "print(complete_the_phrase(\"Do you like playing\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complétion de phrase avec les trigrammes\n",
    "Ici on définit une fonction pour compléter une phrase en utilisant les trigrammes les plus fréquents. Elle prédit les mots suivants jusqu'à atteindre la longueur maximale spécifiée.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "once upon a time when i was just a few days ago i m not\n"
     ]
    }
   ],
   "source": [
    "def complete_the_phrase_trigram(starting_phrase, max_length=15):\n",
    "    current_phrase = starting_phrase.strip()\n",
    "    words = current_phrase.split()\n",
    "    \n",
    "    # Ensure there are enough words for trigram prediction\n",
    "    if len(words) < 2:\n",
    "        return \"Please provide at least two words for the initial phrase.\"\n",
    "    \n",
    "    # Continue until reaching the maximum length\n",
    "    for _ in range(max_length - len(words)):\n",
    "        # Use the last two words for the trigram prediction\n",
    "        last_two_words = ' '.join(words[-2:])\n",
    "        # Find candidates that start with the last two words of the current phrase\n",
    "        candidates = {trigram: freq for trigram, freq in trigram_to_freq.items() if trigram.startswith(last_two_words + ' ')}\n",
    "        if not candidates:\n",
    "            break  # No candidates found, stop the loop\n",
    "        # Pick the most frequent continuation (the third word in the trigram)\n",
    "        next_word = sorted(candidates.items(), key=lambda item: item[1], reverse=True)[0][0].split()[2]\n",
    "        words.append(next_word)\n",
    "    \n",
    "    return ' '.join(words)\n",
    "\n",
    "# Example usage:\n",
    "print(complete_the_phrase_trigram(\"once upon\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classe NGramPredictor\n",
    "Ici on définit une classe `NGramPredictor` pour créer un modèle de n-grammes (séquences de n mots) avec des méthodes pour ajuster le modèle sur des phrases, prédire le mot suivant et compléter une phrase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramPredictor:\n",
    "    def __init__(self, n=2):\n",
    "        self.n = n\n",
    "        self.vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b', ngram_range=(n, n))\n",
    "        self.ngram_to_freq = {}\n",
    "\n",
    "    def fit(self, sentences):\n",
    "        X_ngram = self.vectorizer.fit_transform(sentences)\n",
    "        ngram_frequency = np.asarray(X_ngram.sum(axis=0)).ravel()\n",
    "        self.ngram_to_freq = dict(zip(self.vectorizer.get_feature_names_out(), ngram_frequency))\n",
    "\n",
    "    def predict_next_word(self, previous_words):\n",
    "        previous_words = ' '.join(previous_words.split()[-(self.n-1):]).lower()\n",
    "        candidates = {ngram: freq for ngram, freq in self.ngram_to_freq.items() if ngram.startswith(previous_words + ' ')}\n",
    "        \n",
    "        if not candidates:\n",
    "            return None  # Changed to return None for easier checking\n",
    "        \n",
    "        return max(candidates, key=candidates.get).split()[-1]\n",
    "\n",
    "    def complete_the_phrase(self, starting_phrase, max_length=10):\n",
    "        current_phrase = starting_phrase.strip()\n",
    "        words = current_phrase.split()\n",
    "        \n",
    "        # Adjust for n-gram model\n",
    "        for _ in range(max_length - len(words)):\n",
    "            if len(words) < self.n - 1:\n",
    "                return \"Please provide more words for the initial phrase.\"\n",
    "            \n",
    "            # For n-grams, use the last n-1 words as context\n",
    "            previous_words = ' '.join(words[-(self.n-1):])\n",
    "            next_word = self.predict_next_word(previous_words)\n",
    "            \n",
    "            if not next_word:\n",
    "                break  # No candidates found, stop the loop\n",
    "            \n",
    "            words.append(next_word)\n",
    "        \n",
    "        return ' '.join(words)\n",
    "    \n",
    "    def print_top_ngrams(self, top=10):\n",
    "        for ngram, freq in sorted(self.ngram_to_freq.items(), key=lambda item: item[1], reverse=True)[:top]:\n",
    "            print(f\"N-Gram: '{ngram}', Frequency: {freq}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemple d'utilisation du NGramPredictor\n",
    "Ici on crée une instance de la classe `NGramPredictor` pour les trigrammes et ajuste le modèle sur les phrases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "ngram_predictor = NGramPredictor(n=4)  # For trigrams\n",
    "ngram_predictor.fit(sentences)  # Assuming 'sentences' is a list of sentence strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affichage des n-grammes les plus fréquents et complétion de phrase\n",
    "Ici on affiche les n-grammes les plus fréquents et utilise la méthode `complete_the_phrase` de la classe `NGramPredictor` pour compléter une phrase donnée.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-Gram: 'nigger nigger nigger nigger', Frequency: 3411\n",
      "N-Gram: 'on my talk page', Frequency: 3067\n",
      "N-Gram: 'be blocked from editing', Frequency: 2761\n",
      "N-Gram: 'fuck you fuck you', Frequency: 2681\n",
      "N-Gram: 'you fuck you fuck', Frequency: 2623\n",
      "N-Gram: 'i don t know', Frequency: 2621\n",
      "N-Gram: 'you will be blocked', Frequency: 2549\n",
      "N-Gram: 'if you continue to', Frequency: 2486\n",
      "N-Gram: 'if you have any', Frequency: 2483\n",
      "N-Gram: 'i don t think', Frequency: 2464\n",
      "once upon a time in a steppe far far away\n"
     ]
    }
   ],
   "source": [
    "ngram_predictor.print_top_ngrams()\n",
    "print(ngram_predictor.complete_the_phrase(\"once upon a\", max_length=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Évaluation du modèle\n",
    "Ici on définit une fonction pour évaluer la précision du modèle sur les phrases de test. Elle compare les prédictions du modèle avec les mots réels et calcule la précision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "Context: Thank you for - Expected: understanding. Predicted: your 1\n",
      "None \n",
      "None \n",
      "None \n",
      "Context: I think very - Expected: highly Predicted: early 1\n",
      "Context: think very highly - Expected: of Predicted: of 1\n",
      "Context: very highly of - Expected: you Predicted: the 1\n",
      "Context: highly of you - Expected: and Predicted: and 1\n",
      "Context: of you and - Expected: would Predicted: your 1\n",
      "Context: you and would - Expected: not Predicted: not 1\n",
      "Context: and would not - Expected: revert Predicted: be 1\n",
      "Context: would not revert - Expected: without Predicted: a 1\n",
      "Context: not revert without - Expected: discussion. Predicted: confirmation 1\n",
      "None \n",
      "Context: god this site - Expected: is Predicted: is 2\n",
      "Context: this site is - Expected: horrible. Predicted: a 2\n",
      "None \n",
      "Context: Somebody will invariably - Expected: try Predicted: try 3\n",
      "Context: will invariably try - Expected: to Predicted: to 3\n",
      "Context: invariably try to - Expected: add Predicted: add 3\n",
      "Context: try to add - Expected: Religion? Predicted: some 3\n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "Context: the way people - Expected: have Predicted: have 3\n",
      "Context: way people have - Expected: invariably Predicted: already 3\n",
      "Context: people have invariably - Expected: kept Predicted: kept 3\n",
      "Context: have invariably kept - Expected: adding Predicted: adding 3\n",
      "Context: invariably kept adding - Expected: \"\"Religion\"\" Predicted: religion 3\n",
      "None \n",
      "None \n",
      "None \n",
      "Context: to the Samuel - Expected: Beckett Predicted: beckett 3\n",
      "Context: the Samuel Beckett - Expected: infobox? Predicted: infobox 3\n",
      "None \n",
      "None \n",
      "None \n",
      "Context: And why do - Expected: you Predicted: you 3\n",
      "Context: why do you - Expected: bother Predicted: think 3\n",
      "Context: do you bother - Expected: bringing Predicted: at 3\n",
      "Context: you bother bringing - Expected: up Predicted: up 3\n",
      "Context: bother bringing up - Expected: the Predicted: the 3\n",
      "Context: bringing up the - Expected: long-dead Predicted: arguments 3\n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "Context: making up crap - Expected: on Predicted: believed 3\n",
      "Context: up crap on - Expected: the Predicted: the 3\n",
      "Context: crap on the - Expected: fly. Predicted: board 3\n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "Context: the only explicit - Expected: acknowledgement Predicted: acknowledgement 3\n",
      "Context: only explicit acknowledgement - Expected: in Predicted: in 3\n",
      "Context: explicit acknowledgement in - Expected: the Predicted: the 3\n",
      "Context: acknowledgement in the - Expected: entire Predicted: entire 3\n",
      "Context: in the entire - Expected: Amos Predicted: world 3\n",
      "Context: the entire Amos - Expected: Oz Predicted: oz 3\n",
      "Context: entire Amos Oz - Expected: article Predicted: article 3\n",
      "Context: Amos Oz article - Expected: that Predicted: that 3\n",
      "Context: Oz article that - Expected: he Predicted: he 3\n",
      "Context: article that he - Expected: is Predicted: is 3\n",
      "Context: that he is - Expected: personally Predicted: a 3\n",
      "Context: he is personally - Expected: Jewish Predicted: jewish 3\n",
      "Context: is personally Jewish - Expected: is Predicted: is 3\n",
      "Context: personally Jewish is - Expected: in Predicted: in 3\n",
      "Context: Jewish is in - Expected: the Predicted: the 3\n",
      "Context: is in the - Expected: categories! Predicted: article 3\n",
      "None \n",
      "None \n",
      "Context: It says it - Expected: right Predicted: is 4\n",
      "Context: says it right - Expected: there Predicted: there 4\n",
      "Context: it right there - Expected: that Predicted: are 4\n",
      "Context: right there that - Expected: it Predicted: you 4\n",
      "Context: there that it - Expected: IS Predicted: is 4\n",
      "Context: that it IS - Expected: a Predicted: not 4\n",
      "Context: it IS a - Expected: type. Predicted: very 4\n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "Context: of institution is - Expected: needed Predicted: needed 4\n",
      "Context: institution is needed - Expected: in Predicted: in 4\n",
      "Context: is needed in - Expected: this Predicted: the 4\n",
      "Context: needed in this - Expected: case Predicted: article 4\n",
      "Context: in this case - Expected: because Predicted: the 4\n",
      "Context: this case because - Expected: there Predicted: there 4\n",
      "Context: case because there - Expected: are Predicted: is 4\n",
      "Context: because there are - Expected: three Predicted: no 4\n",
      "Context: there are three - Expected: levels Predicted: articles 4\n",
      "Context: are three levels - Expected: of Predicted: of 4\n",
      "Context: three levels of - Expected: SUNY Predicted: suny 4\n",
      "Context: levels of SUNY - Expected: schools: Predicted: schools 4\n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "Context: Centers and Doctoral - Expected: Granting Predicted: granting 4\n",
      "Context: and Doctoral Granting - Expected: Institutions Predicted: institutions 4\n",
      "Context: Doctoral Granting Institutions - Expected: -State Predicted: state 4\n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "Context: It is needed - Expected: in Predicted: for 4\n",
      "Context: is needed in - Expected: this Predicted: the 4\n",
      "Context: needed in this - Expected: case Predicted: article 4\n",
      "Context: in this case - Expected: to Predicted: the 4\n",
      "Context: this case to - Expected: clarify Predicted: begin 4\n",
      "Context: case to clarify - Expected: that Predicted: that 4\n",
      "Context: to clarify that - Expected: UB Predicted: the 4\n",
      "Context: clarify that UB - Expected: is Predicted: is 4\n",
      "Context: that UB is - Expected: a Predicted: a 4\n",
      "Context: UB is a - Expected: SUNY Predicted: suny 4\n",
      "Context: is a SUNY - Expected: Center. Predicted: center 4\n",
      "None \n",
      "None \n",
      "None \n",
      "Context: It says it - Expected: even Predicted: is 4\n",
      "Context: says it even - Expected: in Predicted: in 4\n",
      "Context: it even in - Expected: Binghamton Predicted: 2014 4\n",
      "Context: even in Binghamton - Expected: University, Predicted: university 4\n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "Context: State University of - Expected: New Predicted: new 4\n",
      "Context: University of New - Expected: York, Predicted: york 4\n",
      "None \n",
      "None \n",
      "None \n",
      "Context: and Stony Brook - Expected: University. Predicted: university 4\n",
      "None \n",
      "None \n",
      "None \n",
      "Context: Stop trying to - Expected: say Predicted: be 4\n",
      "Context: trying to say - Expected: it's Predicted: that 4\n",
      "None \n",
      "None \n",
      "None \n",
      "Context: not because I - Expected: am Predicted: m 4\n",
      "Context: because I am - Expected: totally Predicted: not 4\n",
      "Context: I am totally - Expected: right Predicted: in 4\n",
      "Context: am totally right - Expected: in Predicted: but 4\n",
      "Context: totally right in - Expected: this Predicted: this 4\n",
      "Context: right in this - Expected: case.\" Predicted: case 4\n",
      "None \n",
      "None \n",
      "Context: Before adding a - Expected: new Predicted: new 5\n",
      "Context: adding a new - Expected: product Predicted: section 5\n",
      "Context: a new product - Expected: to Predicted: to 5\n",
      "Context: new product to - Expected: the Predicted: the 5\n",
      "Context: product to the - Expected: list, Predicted: list 5\n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "Context: Before adding a - Expected: new Predicted: new 5\n",
      "Context: adding a new - Expected: product Predicted: section 5\n",
      "Context: a new product - Expected: to Predicted: to 5\n",
      "Context: new product to - Expected: the Predicted: the 5\n",
      "Context: product to the - Expected: list, Predicted: list 5\n",
      "None \n",
      "None \n",
      "None \n",
      "Context: make sure it - Expected: has Predicted: s 5\n",
      "Context: sure it has - Expected: a Predicted: a 5\n",
      "Context: it has a - Expected: wikipedia Predicted: lot 5\n",
      "Context: has a wikipedia - Expected: entry Predicted: article 5\n",
      "Context: a wikipedia entry - Expected: already, Predicted: furthermore 5\n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "Context: relevance and giving - Expected: the Predicted: the 5\n",
      "Context: and giving the - Expected: reader Predicted: facts 5\n",
      "Context: giving the reader - Expected: the Predicted: a 5\n",
      "Context: the reader the - Expected: possibility Predicted: fact 5\n",
      "Context: reader the possibility - Expected: to Predicted: to 5\n",
      "Context: the possibility to - Expected: read Predicted: come 5\n",
      "Context: possibility to read - Expected: more Predicted: more 5\n",
      "Context: to read more - Expected: about Predicted: about 5\n",
      "Context: read more about - Expected: it. Predicted: it 5\n",
      "None \n",
      "None \n",
      "None \n",
      "Context: Otherwise it could - Expected: be Predicted: be 5\n",
      "Context: it could be - Expected: subject Predicted: a 5\n",
      "Context: could be subject - Expected: to Predicted: to 5\n",
      "Context: be subject to - Expected: deletion. Predicted: the 5\n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "Context: this other one - Expected: from Predicted: from 6\n",
      "Context: other one from - Expected: 1897 Predicted: 1897 6\n",
      "None \n",
      "Context: Reason for banning - Expected: throwing Predicted: throwing 7\n",
      "Context: for banning throwing - Expected: == Predicted: this 7\n",
      "None \n",
      "None \n",
      "None \n",
      "Context: This article needs - Expected: a Predicted: to 7\n",
      "Context: article needs a - Expected: section Predicted: lot 7\n",
      "Context: needs a section - Expected: on Predicted: on 7\n",
      "Context: a section on - Expected: /why/ Predicted: the 7\n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "None \n",
      "None \n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, test_sentences):\n",
    "    print(len(test_sentences))\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    counter = 0\n",
    "    for sentence in test_sentences:\n",
    "        counter += 1\n",
    "        words = sentence.split()\n",
    "        # Ensure the sentence has more words than n-1 to make a prediction and have a target\n",
    "        if len(words) >= model.n:\n",
    "            for i in range(model.n - 1, len(words)):\n",
    "                context = ' '.join(words[max(0, i - model.n + 1):i])\n",
    "                actual_next_word = words[i]\n",
    "                predicted_next_word = model.predict_next_word(context)\n",
    "                \n",
    "                if predicted_next_word is not None and predicted_next_word == actual_next_word:\n",
    "                    correct_predictions += 1\n",
    "                total_predictions += 1\n",
    "\n",
    "                if (predicted_next_word is None):\n",
    "                    print (\"None \")\n",
    "                else:\n",
    "                    print(\"Context: \" + context + \" - Expected: \" + words[i] + \" Predicted: \" + predicted_next_word + \" \" + str(counter))\n",
    "        if (counter >= 100):\n",
    "            break\n",
    "    \n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    return accuracy\n",
    "\n",
    "# Assuming you have an instance of NGramPredictor called 'ngram_predictor' and it's already fit\n",
    "# And assuming 'sentences' is your list of test sentences:\n",
    "test_sentences = df_test['comment_text_baseline'].to_list()\n",
    "#print(sentences)\n",
    "test_sentences = test_sentences[:100]\n",
    "# Example usage:\n",
    "tested_predictor = NGramPredictor(n=4)  # For trigrams\n",
    "tested_predictor.fit(sentences)  # Assuming 'sentences' is a list of sentence strings\n",
    "accuracy = evaluate_model(tested_predictor, test_sentences)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
